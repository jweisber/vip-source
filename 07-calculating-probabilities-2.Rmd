# Calculating Probabilities, Part II

We learned rules for $\vee$ and for $\wedge$ back in [Chapter 5][Calculating Probabilities]:

The Addition Rule

:    $\p(A \vee B) = \p(A) + \p(B)$ if $A$ and $B$ are mutually exclusive.

The Multiplication Rule

:    $\p(A \& B) = \p(A) \times \p(B)$ if $A$ and $B$ are independent.

In this chapter we'll learn new, more powerful rules for $\vee$ and $\wedge$. But we'll start with negation, a rule for calculating $\p(\neg A)$.


## The Negation Rule

```{r fig.margin=TRUE, fig.cap="The Negation Rule. $\\p(\\neg A) = 1 - \\p(A)$."}
ggplot() + theme_void() + coord_fixed() +
  xlim(-3,3) + ylim(-2,2) +
  theme(panel.border = element_rect(colour = "black", fill=NA, size=1),
        panel.background = element_rect(fill = "firebrick")) +
  geom_circle(aes(x0 = 0, y0 = 0, r = 1.5), fill = "steelblue") +
  geom_text(aes(x = 0, y = 0, label = "A"), 
            fontface = "italic", size = 10, family=c("serif")) +
  geom_text(aes(x = -2, y = 1.5, label = "~A"), 
            fontface = "italic", size = 10, family = "serif")
```

If there's a 70% chance of rain, then there's a 30% chance it won't rain. In symbols, if $\p(R) = .7$ then $\p(\neg R) = .3$. So the rule for $\p(\neg A)$ is:

The Negation Rule

:   $\p(\neg A) = 1 - \p(A)$.

In terms of an Euler diagram, the probability of $\neg A$ is the size of the red region, outside the $A$ region. So $\p(\neg A)$ is one minus the size of the blue region, $1 - \p(A)$.

`r newthought("It's important")` to notice that this rule can be flipped around, to calculate the probability of a positive statement:

$$ \p(A) = 1 - \p(\neg A). $$

Sometimes we really want to know the probability of $A$, $\p(A)$, but it turns out to be much easier to calculate $\p(\neg A)$ first. Then we use this flipped version of the negation rule to get what we're after.


## The General Addition Rule

The Addition Rule for calculating $\p(A \vee B)$ depends on $A$ and $B$ being mutually exclusive. What if they're not? Then we can use:

The General Addition Rule

:    $\p(A \vee B) = \p(A) + \p(B) - \p(A \wedge B)$.

This rule always applies, whether $A$ and $B$ are mutually exclusive or not.

```{r echo=FALSE, fig.margin=TRUE, fig.cap="The General Addition Rule in an Euler diagram."}

propositions <- data.frame(
    cirx = c(-.75   , .75),
    ciry = c(0      , 0),
    r    = c(1.5    , 1.5),
    labx = c(-2.25  , 2.25),
    laby = c(1      , 1),
    labl = c("A", "B")
)

ggplot(propositions) + 
  theme_void() + coord_fixed() +
  xlim(-3,3) + ylim(-2,2) +
  theme(panel.border = element_rect(colour = "black", fill = NA, size = 1)) +
  geom_circle(aes(x0 = cirx, y0 = ciry, r = r), data = propositions[2,], fill = "firebrick", alpha = .75) +
  geom_circle(aes(x0 = cirx, y0 = ciry, r = r), data = propositions[1,], fill = "steelblue", alpha = .75) +
  geom_circle(aes(x0 = cirx, y0 = ciry, r = r), fill = "transparent") +
  geom_text(aes(x = labx, y = laby, label = labl), 
            fontface = "italic", size = 8, family = "serif")
```

To understand the rule, consider an Euler diagram where $A$ and $B$ are not mutually exclusive. In terms of colour, the size of the $A \vee B$-region is:
$$ 
  \definecolor{left}{RGB}{106,146,187}
  \definecolor{middle}{RGB}{108,122,158}
  \definecolor{right}{RGB}{187,104,105}
  \color{left}{\blacksquare}\color{black}{}
    \,+\,
  \color{middle}{\blacksquare}\color{black}{}
    \,+\,
  \color{right}{\blacksquare}\color{black}{}.
$$
Which is the same as:
$$
  (\color{left}{\blacksquare}\color{black}{}
    \,+\,
  \color{middle}{\blacksquare}\color{black}{})
    \,+\, 
  (\color{right}{\blacksquare}\color{black}{}
    \,+\,
  \color{middle}{\blacksquare}\color{black}{}) 
    \,-\,
  \color{middle}{\blacksquare}\color{black}{}.
$$
In algebraic terms this is:
$$ \p(A) + \p(B) - \p(A \wedge B).$$

To think of it another way, when we add $\p(A) + \p(B)$ to get the size of the $A \vee B$ region, we double-count the $A \wedge B$ region. So we have to subtract out $\p(A \wedge B)$ at the end.

`r newthought("What if")` there is no $A \wedge B$ region? Then $\p(A \wedge B) = 0$, so subtracting it at the end has no effect. Then we just have the old Addition Rule:
$$
  \begin{aligned}
    \p(A \vee B) &= \p(A) + \p(B) - \p(A \wedge B)\\
                 &= \p(A) + \p(B) - 0\\
                 &= \p(A) + \p(B).\\
  \end{aligned}
$$
And this makes sense. If there is no $A \wedge B$ region, that means $A$ and $B$ are mutually exclusive. So the old Addition Rule applies.

That's why we call the new rule the *General* Addition Rule. It applies in general, even when $A$ and $B$ are not mutually exclusive. And in the special case where they are mutually exclusive, it gives the same result as the Addition Rule we already learned.

`r newthought("A tree diagram")` also works to explain the General Addition Rule. Consider this diagram, where we start with branches for $A$ and $\neg A$, then subdivide into branches for $B$ and $\neg B$:

```{r echo=FALSE, fig.cap="Tree diagram with the three $A \\vee B$ leaves marked"}
df_nodes <- rbind(
  data.frame(text = "A", x = .35, y = .75),
  data.frame(text = "~ A", x = .35, y = .25),  
  data.frame(text = "B", x = .725,  y = .9),  
  data.frame(text = "~ B", x = .725,  y = .6),
  data.frame(text = "B", x = .725,  y = .4),
  data.frame(text = "~ B", x = .725,  y = .1)
)

df_segments <- rbind(
  data.frame(x1 = 0, y1 = .5, x2 = .3, y2 = .75),
  data.frame(x1 = 0, y1 = .5, x2 = .3, y2 = .25),  
  data.frame(x1 = .4, y1 = .75, x2 = .68, y2 = .9),  
  data.frame(x1 = .4, y1 = .75, x2 = .68, y2 = .6),
  data.frame(x1 = .4, y1 = .25, x2 = .68, y2 = .4),
  data.frame(x1 = .4, y1 = .25, x2 = .68, y2 = .1)
)

df_leaf_labels <- rbind(
  data.frame(text = "Pr(A&B)", x = .875, y = .9),
  data.frame(text = "Pr(A&~B)", x = .875, y = .6),
  data.frame(text = "Pr(~A&B)", x = .875, y = .4),
  data.frame(text = "Pr(~A&~B)", x = .875, y = .1)
)

ggplot() + coord_fixed() +
  geom_text(aes(x, y, label = text), data = df_nodes, fontface = "italic") + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_segments) +
  geom_text(aes(x, y, label = text), data = df_leaf_labels, fontface = "italic") + 
  geom_emoji(aes(x = 1, y = .9), emoji = "1f603") +
  geom_emoji(aes(x = 1, y = .6), emoji = "1f60e") +
  geom_emoji(aes(x = 1, y = .4), emoji = "1f60d") +
  xlim(0, 1) + ylim(0, 1) +
  theme_void()
```

There are three leaves where $A \vee B$ is true, marked with emoji. If we add $\p(A) + \p(B)$, we're adding the two leaves where $A$ is true (ðŸ˜ƒ, ðŸ˜Ž) to the two leaves where $B$ is true (ðŸ˜ƒ, ðŸ˜). So we've double-counted the $A \wedge B$ leaf (ðŸ˜ƒ). To get $\p(A \vee B)$ then, we have to subtract one of those $A \wedge B$ leaves (ðŸ˜ƒ).

`r newthought("There is a catch")` to the General Addition Rule. You need to know $\p(A \wedge B)$ in order to apply it. Sometimes that information is given to us. But when it's not, we have to figure it out somehow. If $A$ and $B$ are mutually exclusive, then it's easy: $\p(A \wedge B) = 0$. Or, if they're independent, then we can calculate $\p(A \wedge B) = \p(A) \times \p(B)$. But in other cases we have to turn elsewhere.


## The General Multiplication Rule

How can we calculate $\p(A \wedge B)$ in general?

The General Multiplication Rule

:    $\p(A \wedge B) = \p(A \given B) \p(B).$

The intuitive idea is, if you want to know how likely it is $A$ and $B$ will both turn out to be true, first ask yourself how likely $A$ is to be true *if* $B$ is true. Then weight the answer according to $B$'s chances of being true.

Notice, if $A$ and $B$ are independent, then this rule just collapses into the familiar Multiplication rule we already learned. If they're independent, then $\p(A \given B) = \p(A)$ by definition. So substituting into the General Multiplication Rule gives:

$$
  \begin{aligned}
    \p(A \wedge B) &= \p(A \given B) \p(B)\\
                   &= \p(A) \p(B).
  \end{aligned}
$$

So we now have two rules for $\wedge$. The first one only applies when the two sides of the $\wedge$ are independent. The second applies whether they're independent or not. Of course, the second rule ends up being the same as the first one when they are independent.

`r newthought("A tree diagram helps")` us understand this rule too. Recall this problem from [Chapter 6][Conditional Probability], with two urns of coloured marbles:

- Urn X contains 3 black marbles, 1 white.
- Urn Y contains 1 black marble, 3 white.

I flip a fair coin to decide which urn to draw from, heads for Urn B and tails for Urn W. Then I draw one marble at random.

```{r echo=FALSE, fig.cap="Tree diagram for an urn problem"}
df_nodes <- rbind(
  data.frame(text = "H", x = .5, y = .75),
  data.frame(text = "T", x = .5, y = .25),  
  data.frame(text = "B", x = 1,  y = .9),  
  data.frame(text = "W", x = 1,  y = .6),
  data.frame(text = "B", x = 1,  y = .4),
  data.frame(text = "W", x = 1,  y = .1)
)

df_segments <- rbind(
  data.frame(x1 = 0, y1 = .5, x2 = .48, y2 = .75),
  data.frame(x1 = 0, y1 = .5, x2 = .48, y2 = .25),  
  data.frame(x1 = .52, y1 = .75, x2 = .98, y2 = .9),  
  data.frame(x1 = .52, y1 = .75, x2 = .98, y2 = .6),
  data.frame(x1 = .52, y1 = .25, x2 = .98, y2 = .4),
  data.frame(x1 = .52, y1 = .25, x2 = .98, y2 = .1)
)

df_segment_labels <- rbind(
  data.frame(text = "1/2", x = .25, y = .67),
  data.frame(text = "1/2", x = .25, y = .40),  
  data.frame(text = "3/4", x = .75, y = .86),
  data.frame(text = "1/4", x = .75, y = .71),
  data.frame(text = "1/4", x = .75, y = .36),
  data.frame(text = "3/4", x = .75, y = .21)
)

df_leaf_labels <- rbind(
  data.frame(text = "3/8", x = 1.1, y = .9),
  data.frame(text = "1/8", x = 1.1, y = .6),
  data.frame(text = "1/8", x = 1.1, y = .4),
  data.frame(text = "3/8", x = 1.1, y = .1)
)

ggplot() +
  geom_text(aes(x, y, label = text), data = df_nodes, fontface = "italic") + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_segments) + 
  geom_text(aes(x, y, label = text), data = df_segment_labels) + 
  geom_text(aes(x, y, label = text), data = df_leaf_labels, fontface = "bold") + 
  xlim(0, 1.1) + ylim(0, 1) +
  theme_void()
```

Now suppose we want to know the probability the coin will land tails and the marble drawn willl be white, $\p(T \wedge W)$. The General Multiplication Rule tells us the answer is:
$$
  \begin{aligned}
    \p(T \wedge W) &= \p(W \wedge T)\\
                   &= \p(W \given T) \p(T)\\
                   &= 3/4 \times 1/2\\
                   &= 3/8.
  \end{aligned}
$$
In the tree diagram, this corresponds to following the bottom-most path, multiplying the probabilities as we go. And this makes sense: half the time the coin will land tails, and on $3/4$ of those occasions the marble drawn will be white. So, if we were to repeat the experiment again and again, we would get tails followed by a white marble in $3$ out of every $8$ trials.


## Laplace's Urn Puzzle

The same urn scenario was used by [18th Century mathematician Laplace][Strength] in one of his favourite puzzles. He asked what happens if we do *two* draws, with replacement. What's the probability both draws will come up black?

It's tempting to say $1/4$. The probability of drawing a black marble on each draw is $1/2$. So it *seems* the probability of two blacks is just $1/2 \times 1/2 = 1/4$.

But the correct answer is actually $5/16$. Why? Let's use a probability tree again.

```{r echo=FALSE, fig.margin=TRUE, fig.show="hold", fig.cap="Building a probability tree to solve Laplace's urn puzzle"}
df_nodes <- rbind(
  data.frame(text = "X", x = .5, y = .75),
  data.frame(text = "Y", x = .5, y = .25),  
  data.frame(text = "BB", x = 1,  y = .9),  
  data.frame(text = "~BB", x = 1,  y = .6),
  data.frame(text = "BB", x = 1,  y = .4),
  data.frame(text = "~BB", x = 1,  y = .1)
)

df_segments <- rbind(
  data.frame(x1 = 0, y1 = .5, x2 = .48, y2 = .75),
  data.frame(x1 = 0, y1 = .5, x2 = .48, y2 = .25),  
  data.frame(x1 = .52, y1 = .75, x2 = .96, y2 = .9),  
  data.frame(x1 = .52, y1 = .75, x2 = .96, y2 = .6),
  data.frame(x1 = .52, y1 = .25, x2 = .96, y2 = .4),
  data.frame(x1 = .52, y1 = .25, x2 = .96, y2 = .1)
)

df_segment_labels <- rbind(
  data.frame(text = "1/2", x = .25, y = .67),
  data.frame(text = "1/2", x = .25, y = .40),  
  data.frame(text = "9/16", x = .75, y = .86),
  data.frame(text = "7/16", x = .75, y = .71),
  data.frame(text = "1/16", x = .75, y = .36),
  data.frame(text = "15/16", x = .75, y = .21)
)

df_leaf_labels <- rbind(
  data.frame(text = "9/32", x = 1.1, y = .9),
  data.frame(text = "1/32", x = 1.1, y = .4)
)

ggplot() +
  geom_text(aes(x, y, label = text), data = df_nodes[0:2,], fontface = "italic") + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_segments[0:2, ]) + 
  geom_text(aes(x, y, label = text), data = df_segment_labels[0:2, ]) + 
  xlim(0, 1.1) + ylim(0, 1) +
  theme_void()

ggplot() +
  geom_text(aes(x, y, label = text), data = df_nodes[0:4,], fontface = "italic") + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_segments[0:4, ]) + 
  geom_text(aes(x, y, label = text), data = df_segment_labels[0:4, ]) + 
  xlim(0, 1.1) + ylim(0, 1) +
  theme_void()

ggplot() +
  geom_text(aes(x, y, label = text), data = df_nodes, fontface = "italic") + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_segments) + 
  geom_text(aes(x, y, label = text), data = df_segment_labels) + 
  geom_text(aes(x, y, label = text), data = df_leaf_labels, fontface = "bold") + 
  xlim(0, 1.1) + ylim(0, 1) +
  theme_void()
```

Depending on how the coin lands, you could end up drawing either from Urn X or from Urn Y, with equal probability.

If you end up drawing from Urn X, the probability of a black marble on any given draw is $3/4$. Because the draws are independent (we're drawing with replacement), the probability they'll both come up black is $3/4 \times 3/4 = 9/16$.

If instead you end up drawing from Urn Y, the probability of a black marble on any given draw is $1/4$. The draws are still independent though, so the chance of both being black in this case is $1/4 \times 1/4 = 1/16$.

So the probability of drawing two black marbles from Urn X is:
$$
  \begin{aligned}
    \p(X \wedge BB) &= \p(X) \p(BB \given X)\\
                    &= 1/2 \times 9/16\\
                    &= 9/32.
  \end{aligned}
$$
And the probability of drawing two black marbles from Urn Y is:
$$
  \begin{aligned}
    \p(Y \wedge BB) &= \p(Y) \p(BB \given Y)\\
                    &= 1/2 \times 1/16\\
                    &= 1/32.
  \end{aligned}
$$
Now we can apply the Addition Rule to calcualte $\p(BB)$:
$$
  \begin{aligned}
    \p(BB) &= \p(X \wedge BB) + \p(Y \wedge BB)\\
           &= 9/32 + 1/32\\
           &= 5/16.
  \end{aligned}
$$


## The Law of Total Probability

This kind of calculation comes up a lot. Since it would be tedious to figure it out from scratch every time, we make a general rule instead:

The Law of Total Probability

:    $\p(A) = \p(A \given B) \p(B) + \p(A \given \neg B) \p(\neg B)$.

There's an intuitive idea at work here. To figure out how likely $A$ is, consider how likely it would be if $B$ were true, and how likely it would be if $B$ were false. Then weight each of those hypothetically possibilities according to their probabilities.

```{r echo=FALSE, fig.margin=TRUE, fig.cap="The Law of Total Probability calculates the size of the $A$ region by summing its two part."}

propositions <- data.frame(
    cirx = c(-.75   , .75),
    ciry = c(0      , 0),
    r    = c(1.5    , 1.5),
    labx = c(-2.25  , 2.25),
    laby = c(1      , 1),
    labl = c("A", "B")
)

ggplot(propositions) + 
  theme_void() + coord_fixed() +
  xlim(-3,3) + ylim(-2,2) +
  theme(panel.border = element_rect(colour = "black", fill = NA, size = 1)) +
  geom_circle(aes(x0 = cirx, y0 = ciry, r = r), data = propositions[2,], fill = "firebrick", alpha = .75) +
  geom_circle(aes(x0 = cirx, y0 = ciry, r = r), data = propositions[1,], fill = "steelblue", alpha = .75) +
  geom_circle(aes(x0 = cirx, y0 = ciry, r = r), fill = "transparent") +
  geom_text(aes(x = labx, y = laby, label = labl), 
            fontface = "italic", size = 8, family = "serif")
```

We can also use an Euler diagram. The size of the $A$ region is the sum of the $A \wedge B$ region and the $A \wedge \neg B$ region: $\color{middle}{\blacksquare}\color{black}{} + \color{left}{\blacksquare}\color{black}{}$. And each of those regions can be calculated using the General Multiplication Rule. For example, $\p(A \wedge B) = \p(A \given B) \p(B)$. So in algebraic terms we have:
$$
  \begin{aligned}
    \p(A) &= \color{middle}{\blacksquare}\color{black}{} 
             + \color{left}{\blacksquare}\color{black}{}\\
          &= \p(A \wedge B) + \p(A \wedge \neg B)\\
          &= \p(A \given B) \p(B) + \p(A \given \neg B) \p(\neg B).
  \end{aligned}
$$
Which is precisely the Law of Total Probability.

```{r echo=FALSE, fig.margin=TRUE, fig.cap="The Law of Total Probability in a tree diagram"}
df_nodes <- rbind(
  data.frame(text = "A", x = .35, y = .75),
  data.frame(text = "~ A", x = .35, y = .25),  
  data.frame(text = "B", x = .725,  y = .9),  
  data.frame(text = "~ B", x = .725,  y = .6),
  data.frame(text = "B", x = .725,  y = .4),
  data.frame(text = "~ B", x = .725,  y = .1)
)

df_segments <- rbind(
  data.frame(x1 = 0, y1 = .5, x2 = .3, y2 = .75),
  data.frame(x1 = 0, y1 = .5, x2 = .3, y2 = .25),  
  data.frame(x1 = .4, y1 = .75, x2 = .68, y2 = .9),  
  data.frame(x1 = .4, y1 = .75, x2 = .68, y2 = .6),
  data.frame(x1 = .4, y1 = .25, x2 = .68, y2 = .4),
  data.frame(x1 = .4, y1 = .25, x2 = .68, y2 = .1)
)

df_leaf_labels <- rbind(
  data.frame(text = "Pr(A&B)", x = .875, y = .9),
  data.frame(text = "Pr(A&~B)", x = .875, y = .6),
  data.frame(text = "Pr(~A&B)", x = .875, y = .4),
  data.frame(text = "Pr(~A&~B)", x = .875, y = .1)
)

ggplot() + coord_fixed() +
  geom_text(aes(x, y, label = text), data = df_nodes, fontface = "italic") + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_segments) +
  geom_text(aes(x, y, label = text), data = df_leaf_labels, fontface = "italic") + 
  geom_emoji(aes(x = 1, y = .9), emoji = "1f604") +
  geom_emoji(aes(x = 1, y = .6), emoji = "1f638") +
  xlim(0, 1) + ylim(0, 1) +
  theme_void()
```

We can use a tree diagram to illustrate the same reasoning. There are two leaves where $A$ is true, marked ðŸ˜„ and ðŸ˜¸. To get the probability of each leaf we multiply across the branches (that's the General Multiplication Rule). And then to get the total probability for $A$, we add up the two leaves:
$$
  \begin{aligned}
    \p(A) &= ðŸ˜„ + ðŸ˜¸\\
          &= \p(A \wedge B) + \p(A \wedge \neg B)\\
          &= \p(A \given B) \p(B) + \p(A \given \neg B) \p(\neg B).
  \end{aligned}
$$
Once again the result is the Law of Total Probability.


## Example

Every day Professor X either drives her car to campus or takes the bus. Mostly she drives, but one time in four she takes the bus. When she drives, she's on time $80\%$ of the time. When she takes the bus, she's on-time $90\%$ of the time.

What is the probability she'll be on time for class tomorrow?

First let's solve this by just applying the Law of Total Probability directly:
$$
  \begin{aligned}
    \p(O) &= \p(O \given B)\p(B) + \p(O \given D)\p(D)\\
          &= (9/10)(1/4) + (8/10)(3/4)\\
          &= 33/40.
  \end{aligned}
$$

Now let's solve it slightly differently, thinking the problem through from more basic principles.

There are two, mutually exclusive cases where Professor X is on time: one where she takes the bus, one where she drives.
$$ \p(O) = \p(O \wedge B) + \p(O \wedge D). $$
We can use the General Multiplication Rule to calculate the probability she'll take the bus and be on time:
$$ \p(O \wedge B) = \p(O \given B)\p(B). $$
And we can do the same for the probability she'll drive and be on time:
$$ \p(O \wedge D) = \p(O \given D)\p(D)$$
Putting all the pieces together:
$$
  \begin{aligned}
    \p(O) &= \p(O \wedge B) + \p(O \wedge D)\\
          &= \p(O \given B)\p(B) + \p(O \given D)\p(D)\\
          &= (9/10)(1/4) + (8/10)(3/4)\\
          &= 33/40.
  \end{aligned}
$$

Notice that we didn't just get the same answer. The calculation that got us there ended up the same too. Our second approach just reconstructed, from scratch, the reasoning behind the Law of Total Probability. It's a very good idea to understand the rationale behind the Law of Total Probability. But once you get used to the formula, it's also fine to skip straight to applying it directly.

```{r echo=FALSE, fig.margin=TRUE, fig.cap="A probability tree for Professor X"}
df_nodes <- rbind(
  data.frame(text = "B", x = .5, y = .75),
  data.frame(text = "D", x = .5, y = .25),  
  data.frame(text = "O", x = 1,  y = .9),  
  data.frame(text = "~ O", x = 1,  y = .6),
  data.frame(text = "O", x = 1,  y = .4),
  data.frame(text = "~ O", x = 1,  y = .1)
)

df_segments <- rbind(
  data.frame(x1 = 0, y1 = .5, x2 = .48, y2 = .75),
  data.frame(x1 = 0, y1 = .5, x2 = .48, y2 = .25),  
  data.frame(x1 = .52, y1 = .75, x2 = .96, y2 = .9),  
  data.frame(x1 = .52, y1 = .75, x2 = .96, y2 = .6),
  data.frame(x1 = .52, y1 = .25, x2 = .96, y2 = .4),
  data.frame(x1 = .52, y1 = .25, x2 = .96, y2 = .1)
)

df_segment_labels <- rbind(
  data.frame(text = "1/4", x = .25, y = .67),
  data.frame(text = "3/4", x = .25, y = .40),  
  data.frame(text = "9/10", x = .75, y = .86),
  data.frame(text = "1/10", x = .75, y = .71),
  data.frame(text = "8/10", x = .75, y = .36),
  data.frame(text = "2/10", x = .75, y = .21)
)

df_leaf_labels <- rbind(
  data.frame(text = "9/40", x = 1.1, y = .9),
  data.frame(text = "24/40", x = 1.1, y = .4)
)

ggplot() +
  geom_text(aes(x, y, label = text), data = df_nodes, fontface = "italic") + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), data = df_segments) + 
  geom_text(aes(x, y, label = text), data = df_segment_labels) + 
  geom_text(aes(x, y, label = text), data = df_leaf_labels, fontface = "bold") + 
  xlim(0, 1.1) + ylim(0, 1) +
  theme_void()
```

You can also use a tree diagram. Again, the calculation will be the same. But the diagram helps you get started, and it helps you check that you've applied the formula correctly too.

```{block, type='warning'}
Black hole warning: notice that the Law of Total Probability depends on $\p(A \given B)$ and $\p(A \given \neg B)$ both being well-defined. So it only applies when $\p(B) \gt 0$ and $\p(\neg B) \gt 0$.
```


## Exercises {-}

1. In the urn puzzle, what is $\p(H \vee B)$?
2. In a three-urn variation, what is $\p(B)$?
3. Formulate a three-case version of the LTP. Explain why this equation is true.